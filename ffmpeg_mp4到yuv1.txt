// 解码流程，多看多理解。
    // 解压缩前的数据对象
    AVPacket *packet = av_packet_alloc();
    // 解码后数据对象
    AVFrame *frame = av_frame_alloc();
    AVFrame *yuvFrame = av_frame_alloc();
 
    // 为yuvFrame缓冲区分配内存，只有指定了AVFrame的像素格式、画面大小才能真正分配内存
    int buffer_size = av_image_get_buffer_size(AV_PIX_FMT_YUV420P, pCodecContext->width, pCodecContext->height, 1);
    uint8_t *out_buffer = (uint8_t *)av_malloc((size_t) buffer_size);
    // 初始化yuvFrame缓冲区
    av_image_fill_arrays(yuvFrame->data, yuvFrame->linesize, out_buffer,
                         AV_PIX_FMT_YUV420P, pCodecContext->width, pCodecContext->height, 1 );
    // yuv输出文件
    FILE* fp_yuv = fopen(output_path_cstr,"wb");
    // test：264输出文件
    char save264str[100]={0};
    sprintf(save264str, "%s", "/storage/emulated/0/10s_test.h264");
    FILE* fp_264 = fopen(save264str,"wb");
 
    //用于像素格式转换或者缩放
    struct SwsContext *sws_ctx = sws_getContext(
            pCodecContext->width, pCodecContext->height, pCodecContext->pix_fmt,
            pCodecContext->width, pCodecContext->height, AV_PIX_FMT_YUV420P,
            SWS_BICUBIC, NULL, NULL, NULL); //SWS_BILINEAR
 
    int ret, frameCount = 0;
    // 5. 循环读取视频数据的分包 AVPacket
    while(av_read_frame(pFormatContext, packet) >= 0)
    {
        if(packet->stream_index == video_stream_idx)
        {
            // test：h264数据写入本地文件
            fwrite(packet->data, 1, (size_t) packet->size, fp_264);
            //AVPacket->AVFrame
            ret = avcodec_send_packet(pCodecContext, packet);
            if(ret < 0){
                LOGE("avcodec_send_packet：%d\n", ret);
                continue;
            }
            while(ret >= 0) {
                ret = avcodec_receive_frame(pCodecContext, frame);
                if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF){
                    LOGD("avcodec_receive_frame：%d\n", ret);
                    break;
                }else if (ret < 0) {
                    LOGW("avcodec_receive_frame：%d\n", AVERROR(ret));
                    goto end;  //end处进行资源释放等善后处理
                }
                if (ret >= 0)
                {   //frame->yuvFrame (调整缩放)
                    sws_scale(sws_ctx,
                              (const uint8_t* const*)frame->data, frame->linesize, 0, frame->height,
                              yuvFrame->data, yuvFrame->linesize);
                    //向YUV文件保存解码之后的帧数据
                    //AVFrame->YUV，一个像素包含一个Y
                    int y_size = frame->width * frame->height;
                    fwrite(yuvFrame->data[0], 1, (size_t) y_size, fp_yuv);
                    fwrite(yuvFrame->data[1], 1, (size_t) y_size/4, fp_yuv);
                    fwrite(yuvFrame->data[2], 1, (size_t) y_size/4, fp_yuv);
                    frameCount++ ;
                }
            }
        }
        av_packet_unref(packet);
    }
    LOGI("总共解码%d帧",frameCount++);
